{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier,StackingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score,classification_report\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import KFold,StratifiedKFold, GroupKFold,train_test_split\nimport gc\nimport datetime\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nnp.random.seed(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data = pd.read_csv(\"/kaggle/input/policy_data.csv\")\npayment_history = pd.read_csv(\"/kaggle/input/payment_history.csv\")\nclient_data = pd.read_csv(\"/kaggle/input/client_data.csv\")\nsample_sub = pd.read_csv(\"/kaggle/input/sample_sub.csv\")\ntrain = pd.read_csv(\"/kaggle/input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data['NPR_PREMIUM']=policy_data['NPR_PREMIUM'].fillna(policy_data['NPR_PREMIUM'].mean())\npolicy_data['NPR_SUMASSURED']=policy_data['NPR_SUMASSURED'].fillna(policy_data['NPR_SUMASSURED'].mean())\npolicy_data['NLO_AMOUNT']=policy_data['NLO_AMOUNT'].fillna(policy_data['NLO_AMOUNT'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"payment_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"payment_history['AMOUNTPAID']=payment_history['AMOUNTPAID'].fillna(payment_history['AMOUNTPAID'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"client_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"client_data['NAD_ADDRESS1']=client_data['NAD_ADDRESS1'].fillna(method='bfill')\nclient_data['NAD_ADDRESS2']=client_data['NAD_ADDRESS2'].fillna(method='bfill')\nclient_data['NPH_LASTNAME']=client_data['NPH_LASTNAME'].fillna(method='bfill')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"policy_data=policy_data.drop_duplicates( \"Policy ID\" , keep='first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(left=train, right=policy_data, how='left', left_on='Policy ID', right_on='Policy ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"payment_history=payment_history.drop_duplicates( \"Policy ID\" , keep='first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(left=train_df, right=payment_history, how='left', left_on='Policy ID', right_on='Policy ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"client_data=client_data.drop_duplicates( \"Policy ID\" , keep='first')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(left=train_df, right=client_data, how='left', left_on='Policy ID', right_on='Policy ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=['DATEPAID','POSTDATE','PREMIUMDUEDATE','NPH_TITLE','NPH_LASTNAME_y','NPH_SEX','NPH_BIRTHDATE','NAD_ADDRESS1','NAD_ADDRESS2']\nfor i in k:\n    train_df[i]=train_df[i].fillna(method='bfill')\ntrain_df['AMOUNTPAID']=train_df['AMOUNTPAID'].fillna(train_df['AMOUNTPAID'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=[]\nfor i in train_df['Lapse Year']:\n    if i=='?':\n        c.append(2020)\n    else:\n        c.append(i)\ntrain_df['Lapse Year']=c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=['NP2_EFFECTDATE','DATEPAID','POSTDATE','PREMIUMDUEDATE']\nfor i in k:\n  train_df[i] = pd.to_datetime(train_df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=['NP2_EFFECTDATE','DATEPAID','POSTDATE','PREMIUMDUEDATE']\nfor i in k:\n  train_df[i+'_'+'year'] = train_df[i].dt.year\n  train_df[i+'_'+'day'] = train_df[i].dt.day\n  train_df[i+'_'+'weekofyear'] = train_df[i].dt.weekofyear\n  train_df[i+'_'+'month'] = train_df[i].dt.month\n  train_df[i+'_'+'dayofweek'] = train_df[i].dt.dayofweek\n  train_df[i+'_'+'weekend'] = (train_df[i].dt.weekday >=5).astype(int)\n  train_df[i+'_'+'hour'] = train_df[i].dt.hour\n  train_df[i+'_'+'minute'] = train_df[i].dt.minute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=['NP2_EFFECTDATE','DATEPAID','POSTDATE','PREMIUMDUEDATE']\nfor i in k:\n    del train_df[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['NP2_EFFECTDATE_year'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train_df.loc[train_df['NP2_EFFECTDATE_year'] != 2020]\ntest=train_df.loc[train_df['NP2_EFFECTDATE_year'] == 2020]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=train_df.loc[train_df['Lapse'] != '1']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test_df['Lapse']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=['PPR_PRODCD','NPH_LASTNAME_x','NLO_TYPE','NPH_TITLE','NPH_LASTNAME_y','NPH_SEX','NPH_BIRTHDATE','NAD_ADDRESS1','NAD_ADDRESS2','AAG_AGCODE','PCL_LOCATCODE','OCCUPATION','CATEGORY']\nfor i in c:\n  loc = np.append(train[i].values, test[i].values, axis=0)\n  from sklearn.preprocessing import LabelEncoder\n  l=LabelEncoder()\n  l.fit(list(set(loc)))\n  train[i]=l.transform(train[i])\n  test_df[i]=l.transform(test_df[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Lapse Year']=train['Lapse Year'].astype(int)\ntest_df['Lapse Year']=test_df['Lapse Year'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=test['Policy ID']\ndel train['Policy ID']\ndel test_df['Policy ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d=train['Lapse']\ndel train['Lapse']\ntrain['Lapse']=d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=[]\nfor i in train['Lapse']:\n    if i=='?':\n        m.append(1)\n    else:\n        m.append(0)\ntrain['Lapse']=m","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_df.drop(labels=['Lapse'], axis=1)\ny = train_df['Lapse'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_cv, y_train, y_cv = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train.shape, y_train.shape, X_cv.shape, y_cv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\ntrain_data = lgb.Dataset(X_train, label=y_train)\ntest_data = lgb.Dataset(X_cv, label=y_cv)\n\nparam = {'objective': 'multiclass',\n         'num_class': 2,\n         'boosting': 'gbdt',  \n         'metric': 'multi_logloss',\n         'learning_rate': 0.01, \n         'num_iterations': 100,\n         'num_leaves': 100,\n         'max_depth': -1,\n         'min_data_in_leaf': 15,\n         'bagging_fraction':0.9,\n         'bagging_freq': 1,\n         'feature_fraction': 0.7,\n         'lambda_l2': 0.8,\n         'min_data_per_group': 75,\n         'max_bin': 255,\n         'is_unbalance':False\n         }\n\nclf = lgb.train(params=param, \n                early_stopping_rounds=200,\n                verbose_eval=100,\n                train_set=train_data,\n                valid_sets=[test_data])\n\ny_pred = clf.predict(X_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"log_loss(y_cv, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfeature_imp = pd.DataFrame(sorted(zip(clf.feature_importance(), X.columns), reverse=True)[:], columns=['Value','Feature'])\nplt.figure(figsize=(10,10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\nplt.title('LightGBM Features')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(data=y_pred, columns=sample_sub.columns)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n\n        \"Policy ID\": sample_sub['Policy ID'],\n        \"Lapse\": submission['Policy ID']\n    })\nsubmission.to_csv('./dartf.csv', index=False)\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
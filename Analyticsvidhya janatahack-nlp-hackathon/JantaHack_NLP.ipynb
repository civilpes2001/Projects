{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.text import *\nfrom fastai.imports import *\nfrom fastai.text import *\nfrom fastai import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/janata-data/test.csv')\ntrain = pd.read_csv('/kaggle/input/janata-data/train.csv')\ngame = pd.read_csv('/kaggle/input/janata-data/game_overview.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.merge(game, on='title', how='left')\ntest=test.merge(game, on='title', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text']=train['user_review']+' '+ train['title']+' '+train['developer']+' '+train['publisher']+' '+train['tags']+' '+train['overview']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['text']=test['user_review']+' '+ test['title']+' '+test['developer']+' '+test['publisher']+' '+test['tags']+' '+test['overview']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train['user_review']\ndel train['title']\ndel train['developer']\ndel train['publisher']\ndel train['tags']\ndel train['overview']\ndel train['year']\ndel train['review_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cc=test['review_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del test['user_review']\ndel test['title']\ndel test['developer']\ndel test['publisher']\ndel test['tags']\ndel test['overview']\ndel test['year']\ndel test['review_id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train['user_suggestion']\ndel train['user_suggestion']\ntrain['user_suggestion']=df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\n\nsns.countplot(x='user_suggestion', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)   \n    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)   \n    text = re.sub(r'www.[^ ]+', '', text)  \n    text = re.sub(r'[a-zA-Z0-9]*www[a-zA-Z0-9]*com[a-zA-Z0-9]*', '', text)  \n    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n    text = [token for token in text.split() if len(token) > 2]\n    text = ' '.join(text)\n    return text\n\ntrain['text'] = train['text'].apply(clean_text)\ntest['text'] = test['text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_seed(seed_value):\n    import random \n    random.seed(seed_value)  \n    import numpy as np\n    np.random.seed(seed_value)  \n    import torch\n    torch.manual_seed(seed_value)  \n    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value)  \n        torch.backends.cudnn.deterministic = True   \n        torch.backends.cudnn.benchmark = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/janata-data/')\npath.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.metrics import accuracy_score \ny_pred_totcb = []\nfrom sklearn.model_selection import KFold, RepeatedKFold\nfold = KFold(n_splits=15, shuffle=True, random_state=0)\ni=1\n\nfor train_index, test_index in fold.split(train):\n    \n    train_df = train.iloc[train_index]\n    valid_df = train.iloc[test_index]\n\n    random_seed(10)\n    \n    data_lm = TextLMDataBunch.from_df(Path(path), train_df, valid_df, test, text_cols=[0], bs=32)\n    data_clas = TextClasDataBunch.from_df(Path(path), train_df, valid_df, test, text_cols=[0], label_cols=1, bs=32)\n    \n    learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.4, model_dir='/tmp/model/')\n    learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))\n    learn.unfreeze()\n    learn.fit_one_cycle(9, 1e-3, moms=(0.8,0.7))\n    learn.save_encoder('model_enc')\n    \n    learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.4, model_dir='/tmp/model/')\n    learn.load_encoder('model_enc')\n    learn.fit_one_cycle(1, 1e-2, moms=(0.8, 0.7))\n    learn.freeze_to(-2)\n    learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n    learn.freeze_to(-3)\n    learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n    learn.unfreeze()\n    learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n   \n    log_preds, test_labels = learn.get_preds(ds_type=DatasetType.Test, ordered=True)\n    preds = np.argmax(log_preds, 1)\n    y_pred_totcb.append(preds)\n    print(f'fold {i} completed')\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_totcb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"review_id\": cc,\n        \"user_suggestion\": y_pred_totcb[0]\n    })\nsubmission.to_csv('./Av_nlp.csv', index=False)\nprint(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2nd Method"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport re\nimport nltk\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nnltk_stopwords = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = text.lower()\n    text = re.sub(r'@[a-zA-Z0-9_]+', '', text)   \n    text = re.sub(r'https?://[A-Za-z0-9./]+', '', text)   \n    text = re.sub(r'www.[^ ]+', '', text)  \n    text = re.sub(r'[a-zA-Z0-9]*www[a-zA-Z0-9]*com[a-zA-Z0-9]*', '', text)  \n    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n    text = [token for token in text.split() if len(token) > 2]\n    text = ' '.join(text)\n    return text\n\ntrain['text'] = train['text'].apply(clean_text)\ntest['text'] = test['text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split\nX_train, X_cv, y_train, y_cv = train_test_split(train['text'], train['text'], test_size=0.1, stratify=train['user_suggestion'], \n                                                random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vect = TfidfVectorizer(analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, \n                             min_df=3, max_features=None, binary=False, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_tfidf = tfidf_vect.fit_transform(X_train)\nX_cv_tfidf = tfidf_vect.transform(X_cv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import f1_score, accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGDClassifier(loss='log', max_iter=100, random_state=101, class_weight='balanced')\novr = OneVsRestClassifier(sgd)\novr.fit(X_train_tfidf, y_train)\ny_pred_class = ovr.predict(X_cv_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('f1_score       :', f1_score(y_cv, y_pred_class, average='macro'))\nprint('accuracy score :', accuracy_score(y_cv, y_pred_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vect = TfidfVectorizer(analyzer='word', stop_words=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), max_df=1.0, \n                             min_df=3, max_features=None, binary=False, norm='l2', use_idf=True, smooth_idf=True, sublinear_tf=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_text = list(train['text'].values) + list(test['text'].values)\ntfidf_vect.fit(full_text)\n\nX_train_tfidf = tfidf_vect.transform(train['text'])\nX_test_tfidf = tfidf_vect.transform(test['text'])\n\ny_train = train['user_suggestion']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.linear_model import SGDClassifier\nsgd = SGDClassifier(loss='log', max_iter=200, random_state=0, class_weight='balanced')\novr = OneVsRestClassifier(sgd)\novr.fit(X_train_tfidf, y_train)\ny_pred_class = ovr.predict(X_test_tfidf)\ny_pred_class","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\n        \"review_id\": cc,\n        \"user_suggestion\": y_pred_class\n    })\nsubmission.to_csv('./Av_nlp.csv', index=False)\nprint(submission)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":4}